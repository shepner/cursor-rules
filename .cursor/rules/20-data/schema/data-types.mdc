---
description: Guidelines for handling data types and type conversions
globs: ["*.py", "*.sql", "*.json", "*.yaml", "*.yml"]
alwaysApply: true
---
# Data Types Guidelines

Rules for consistent data type handling and conversions across the codebase.

<rule>
name: data_types
description: Standards for handling data types, conversions, and validation
filters:
  # Match Python files
  - type: file_extension
    pattern: "\\.py$"
  # Match SQL files
  - type: file_extension
    pattern: "\\.sql$"
  # Match config files
  - type: file_extension
    pattern: "\\.(json|ya?ml)$"
  # Match data type related content
  - type: content
    pattern: "(dtype|astype|convert|cast|type)"

actions:
  - type: suggest
    message: |
      When handling data types:

      1. BigQuery Type Mapping:
         - Use INTEGER instead of INT64 for integer fields
         - Use FLOAT instead of FLOAT64 for floating-point fields
         - Use TIMESTAMP for datetime fields
         - Use BOOLEAN for boolean fields
         - Use STRING for text fields

      2. Pandas DataFrame Conversions:
         - Always check column types before and after conversion using df.dtypes.to_dict()
         - Use pd.to_numeric(errors='coerce') for numeric conversions
         - Use astype('Int64') for nullable integer columns
         - Log raw values before attempting any type conversion
         - Handle NULL/None values explicitly before type conversion
         - Verify data type consistency after conversion

      3. Type Validation:
         - Validate all column types match BigQuery schema
         - Check for type mismatches before upload
         - Handle type conversion errors gracefully
         - Log type conversion failures with sample data
         - Ensure consistent type mapping across all operations

examples:
  - input: |
      # Bad: Inconsistent type handling
      df['value'] = df['value'].astype(float)
      bq_table.schema = [
          bigquery.SchemaField("value", "FLOAT64"),
      ]

      # Good: Consistent type handling with validation
      def convert_and_validate(df, column, target_type):
          original_values = df[column].head()
          logging.debug(f"Converting {column}, sample values: {original_values}")
          
          if target_type == 'FLOAT':
              df[column] = pd.to_numeric(df[column], errors='coerce')
              df[column] = df[column].astype('float64')
          # ... handle other types

          logging.debug(f"Converted {column} to {df[column].dtype}")
          return df

metadata:
  priority: high
  version: 1.0
  tags:
    - data-types
    - conversion
    - validation
  changelog:
    - 1.0: Initial version with comprehensive type handling guidelines 